{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5894a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from models.yolo import ZoominHead,MultiHead,Detect, Model\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import check_version\n",
    "import copy\n",
    "from models.tf import TFModel,TFDetect,TFConv2d\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "# from model.tf import TFD\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ba7f110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5s-anchortune-3 summary: 157 layers, 6040633 parameters, 0 gradients, 13.1 GFLOPs\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv :  ListWrapper([25, 3, 6, 6])\n",
      "conv :  ListWrapper([55, 25, 3, 3])\n",
      "conv :  ListWrapper([24, 55, 1, 1])\n",
      "conv :  ListWrapper([27, 55, 1, 1])\n",
      "conv :  ListWrapper([40, 51, 1, 1])\n",
      "conv :  ListWrapper([32, 24, 1, 1])\n",
      "conv :  ListWrapper([24, 32, 3, 3])\n",
      "conv :  ListWrapper([117, 40, 3, 3])\n",
      "conv :  ListWrapper([58, 117, 1, 1])\n",
      "conv :  ListWrapper([60, 117, 1, 1])\n",
      "conv :  ListWrapper([110, 118, 1, 1])\n",
      "conv :  ListWrapper([64, 58, 1, 1])\n",
      "conv :  ListWrapper([58, 64, 3, 3])\n",
      "conv :  ListWrapper([64, 58, 1, 1])\n",
      "conv :  ListWrapper([58, 64, 3, 3])\n",
      "conv :  ListWrapper([255, 110, 3, 3])\n",
      "conv :  ListWrapper([127, 255, 1, 1])\n",
      "conv :  ListWrapper([127, 255, 1, 1])\n",
      "conv :  ListWrapper([252, 254, 1, 1])\n",
      "conv :  ListWrapper([128, 127, 1, 1])\n",
      "conv :  ListWrapper([127, 128, 3, 3])\n",
      "conv :  ListWrapper([128, 127, 1, 1])\n",
      "conv :  ListWrapper([127, 128, 3, 3])\n",
      "conv :  ListWrapper([128, 127, 1, 1])\n",
      "conv :  ListWrapper([127, 128, 3, 3])\n",
      "conv :  ListWrapper([512, 252, 3, 3])\n",
      "conv :  ListWrapper([254, 512, 1, 1])\n",
      "conv :  ListWrapper([256, 512, 1, 1])\n",
      "conv :  ListWrapper([500, 510, 1, 1])\n",
      "conv :  ListWrapper([256, 254, 1, 1])\n",
      "conv :  ListWrapper([254, 256, 3, 3])\n",
      "conv :  ListWrapper([242, 500, 1, 1])\n",
      "conv :  ListWrapper([501, 968, 1, 1])\n",
      "conv :  ListWrapper([251, 501, 1, 1])\n",
      "debug concat :  512\n",
      "conv :  ListWrapper([128, 503, 1, 1])\n",
      "conv :  ListWrapper([128, 503, 1, 1])\n",
      "conv :  ListWrapper([232, 256, 1, 1])\n",
      "conv :  ListWrapper([128, 128, 1, 1])\n",
      "conv :  ListWrapper([128, 128, 3, 3])\n",
      "conv :  ListWrapper([120, 232, 1, 1])\n",
      "debug concat :  256\n",
      "conv :  ListWrapper([60, 230, 1, 1])\n",
      "conv :  ListWrapper([62, 230, 1, 1])\n",
      "conv :  ListWrapper([85, 122, 1, 1])\n",
      "conv :  ListWrapper([64, 60, 1, 1])\n",
      "conv :  ListWrapper([60, 64, 3, 3])\n",
      "conv :  ListWrapper([120, 85, 3, 3])\n",
      "debug concat :  256\n",
      "conv :  ListWrapper([107, 240, 1, 1])\n",
      "conv :  ListWrapper([113, 240, 1, 1])\n",
      "conv :  ListWrapper([154, 220, 1, 1])\n",
      "conv :  ListWrapper([128, 107, 1, 1])\n",
      "conv :  ListWrapper([107, 128, 3, 3])\n",
      "conv :  ListWrapper([207, 154, 3, 3])\n",
      "debug concat :  512\n",
      "conv :  ListWrapper([217, 458, 1, 1])\n",
      "conv :  ListWrapper([224, 458, 1, 1])\n",
      "conv :  ListWrapper([229, 441, 1, 1])\n",
      "conv :  ListWrapper([256, 217, 1, 1])\n",
      "conv :  ListWrapper([217, 256, 3, 3])\n",
      "tf.Tensor([          8          16          32], shape=(3,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24      [17, 20, 23]  1     29667  models.yolo.Detect                      [28, [[16, 30], [62, 45], [156, 198]], [128, 256, 512], (320, 320)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug conv2d  128 33 torch.Size([33, 85, 1, 1])\n",
      "conv2d :  [33, 85, 1, 1]\n",
      "debug conv2d  256 33 torch.Size([33, 154, 1, 1])\n",
      "conv2d :  [33, 154, 1, 1]\n",
      "debug conv2d  512 33 torch.Size([33, 229, 1, 1])\n",
      "conv2d :  [33, 229, 1, 1]\n",
      "(<tf.Tensor: shape=(1, 2100, 33), dtype=float32, numpy=\n",
      "array([[[   0.014723,    0.014237,    0.038613, ...,    0.013105,    0.021042,    0.018722],\n",
      "        [   0.038183,    0.014657,    0.075949, ...,    0.012904,    0.021552,    0.022214],\n",
      "        [   0.059945,    0.013046,    0.096489, ...,    0.010223,    0.026915,    0.030564],\n",
      "        ...,\n",
      "        [    0.75713,     0.92997,     0.61608, ...,    0.050578,    0.044582,    0.077545],\n",
      "        [    0.85769,     0.92934,     0.53476, ...,     0.04519,    0.038642,    0.072902],\n",
      "        [    0.94518,     0.93003,     0.48559, ...,    0.042337,    0.037552,    0.076601]]], dtype=float32)>,) (1, 2100, 33)\n",
      "(1, 2100, 4) (1, 2100, 28)\n"
     ]
    }
   ],
   "source": [
    "yolo_model = attempt_load('../runs/train/prune-66-finetune-carpart-add-car-v2-anchor-tune-3-od-od/weights/best.pt',fuse=True)\n",
    "tfmodel = TFModel(cfg=yolo_model.yaml,model=yolo_model,nc=yolo_model.nc,imgsz=(320,320))\n",
    "\n",
    "# print(tfmodel.model.layers[24].m[0].conv.get_weights())\n",
    "\n",
    "im = tf.zeros((1,320,320 , 3))\n",
    "b,s = tfmodel.predict(im)\n",
    "print(b.shape,s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab9268b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2931.0583>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins = [tf.ones((1,40,40 , 85)),tf.ones((1,20,20 , 154)),tf.ones((1,10,10 , 229))]\n",
    "tf.math.reduce_sum(detect(ins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f11c3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([85, 154, 229])\n"
     ]
    }
   ],
   "source": [
    "detect.ch = [85,154,229]\n",
    "print(detect.ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9fcb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFZoominHead(keras.layers.Layer):\n",
    "    def __init__(self,torch_module):\n",
    "        super().__init__()\n",
    "        with torch.no_grad():\n",
    "            c2,c1,k = torch_module.conv.weight.shape[:-1]\n",
    "            self.conv = TFConv2d(c1,c2,k,bias=True,w=torch_module.conv)\n",
    "            self.act_conv = lambda x: keras.activations.swish(x)\n",
    "            self.pool = keras.layers.AveragePooling2D(2)\n",
    "            self.flatten = keras.layers.Flatten()\n",
    "            self.ln1 = keras.layers.Dense(25,use_bias=True,\n",
    "                            kernel_initializer=keras.initializers.Constant(torch_module.ln1.weight.permute(1,0).numpy()),\n",
    "                            bias_initializer=keras.initializers.Constant(torch_module.ln1.bias.numpy()))\n",
    "        \n",
    "            self.act1 = lambda x: keras.activations.swish(x)\n",
    "            self.ln2 = keras.layers.Dense(2,use_bias=True,\n",
    "                                    kernel_initializer=keras.initializers.Constant(torch_module.ln2.weight.permute(1,0).numpy()),\n",
    "                                    bias_initializer=keras.initializers.Constant(torch_module.ln2.bias.numpy()))\n",
    "            self.softmax = keras.layers.Softmax()\n",
    "            \n",
    "    def call(self,inputs):\n",
    "        inputs = self.act_conv(self.conv(inputs))\n",
    "        inputs = self.pool(inputs)\n",
    "        inputs = self.flatten(inputs)\n",
    "        \n",
    "        inputs = self.ln2(self.act1(self.ln1(inputs)))\n",
    "        \n",
    "        inputs = self.softmax(inputs)[:,0]\n",
    "        \n",
    "        return inputs\n",
    "    \n",
    "class TFMuliHead(TFDetect):\n",
    "    # YOLOv5 Segment head for segmentation models\n",
    "    def __init__(self, tfdetect_module,zoomin_module):\n",
    "        super().__init__(tfdetect_module.nc, tfdetect_module.anchors, tfdetect_module.ch, tfdetect_module.imgsz)\n",
    "        self.m = tfdetect_module.m\n",
    "        self.detect = TFDetect.call\n",
    "        self.stride = tfdetect_module.stride\n",
    "        self.nl = tfdetect_module.nl\n",
    "        self.na = tfdetect_module.na\n",
    "        self.grid = tfdetect_module.grid\n",
    "        self.anchors = tfdetect_module.anchors\n",
    "        self.anchor_grid = tfdetect_module.anchor_grid\n",
    "        \n",
    "        self.i = tfdetect_module.i\n",
    "        self.f = tfdetect_module.f\n",
    "        self.t = str(type(self))[8:-2].replace('__main__.','')\n",
    "#         print(self.t,self.i,self.f)\n",
    "        \n",
    "        self.zoomin_head = zoomin_module\n",
    "        \n",
    "\n",
    "    def call(self, x):\n",
    "        z = self.zoomin_head(x[-1])\n",
    "        x = self.detect(self, x)\n",
    "        \n",
    "        return (x[0],z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "110e2ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug conv2d  229 1 torch.Size([1, 229, 1, 1])\n",
      "conv2d :  [1, 229, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# detect module\n",
    "detect = tfmodel.model.layers[24]\n",
    "detect.ch = [85,154,229]\n",
    "\n",
    "# zoomin module\n",
    "ckpt = torch.load('zoomin_model.pth')\n",
    "torch_zoomin = ZoominHead()\n",
    "torch_zoomin.load_state_dict(ckpt)\n",
    "\n",
    "tf_zoomin = TFZoominHead(torch_zoomin)\n",
    "\n",
    "\n",
    "mh = TFMuliHead(detect,tf_zoomin)\n",
    "new_sequantail = tfmodel.model.layers[:-1]\n",
    "new_sequantail.append(mh)\n",
    "tfmodel.model = keras.Sequential(new_sequantail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d25ef08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 2100, 33), dtype=float32, numpy=\n",
      "array([[[   0.014723,    0.014237,    0.038613, ...,    0.013105,    0.021042,    0.018722],\n",
      "        [   0.038183,    0.014657,    0.075949, ...,    0.012904,    0.021552,    0.022214],\n",
      "        [   0.059945,    0.013046,    0.096489, ...,    0.010223,    0.026915,    0.030564],\n",
      "        ...,\n",
      "        [    0.75713,     0.92997,     0.61608, ...,    0.050578,    0.044582,    0.077545],\n",
      "        [    0.85769,     0.92934,     0.53476, ...,     0.04519,    0.038642,    0.072902],\n",
      "        [    0.94518,     0.93003,     0.48559, ...,    0.042337,    0.037552,    0.076601]]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([  1.438e-06], dtype=float32)>) (1, 2100, 33)\n",
      "(1, 2100, 4) (1, 2100, 28) tf.Tensor([  1.438e-06], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "im = tf.zeros((1,320,320 , 3))\n",
    "b,s,zoomin = tfmodel.predict(im)\n",
    "print(b.shape,s.shape,zoomin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "476d6cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(<tf.Tensor: shape=(1, 2100, 33), dtype=float32, numpy=\n",
      "array([[[   0.012407,    0.010698,    0.057826, ...,   0.0061914,   0.0048229,     0.01183],\n",
      "        [   0.037407,    0.010698,    0.057826, ...,   0.0061914,   0.0048229,     0.01183],\n",
      "        [   0.062407,    0.010698,    0.057826, ...,   0.0061914,   0.0048229,     0.01183],\n",
      "        ...,\n",
      "        [    0.75088,     0.95161,     0.39843, ...,   0.0028679,   0.0012659,    0.043598],\n",
      "        [    0.85088,     0.95161,     0.39843, ...,   0.0028679,   0.0012659,    0.043598],\n",
      "        [    0.95088,     0.95161,     0.39843, ...,   0.0028679,   0.0012659,    0.043598]]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([    0.43998], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "detect = tfmodel.model.layers[24]\n",
    "print(detect.training)\n",
    "ins = [tf.ones((1,40,40 , 85)),tf.ones((1,20,20 , 154)),tf.ones((1,10,10 , 229))]\n",
    "print(detect(ins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d323647e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320, 320]\n",
      "(<KerasTensor: shape=(1, 2100, 33) dtype=float32 (created by layer 'tf_muli_head_3')>, <KerasTensor: shape=(1,) dtype=float32 (created by layer 'tf_muli_head_3')>) (1, 2100, 33)\n",
      "debug shape output :  (<KerasTensor: shape=(1, 2100, 4) dtype=float32 (created by layer 'tf.concat_2')>, <KerasTensor: shape=(1, 2100, 28) dtype=float32 (created by layer 'tf.math.multiply_2')>, <KerasTensor: shape=(1,) dtype=float32 (created by layer 'tf_muli_head_3')>)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(1, 320, 320, 3)]   0           []                               \n",
      "                                                                                                  \n",
      " tf_conv_171 (TFConv)           (1, 160, 160, 25)    2725        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf_conv_172 (TFConv)           (1, 80, 80, 55)      12430       ['tf_conv_171[0][0]']            \n",
      "                                                                                                  \n",
      " tfc3_24 (TFC3)                 (1, 80, 80, 40)      12672       ['tf_conv_172[0][0]']            \n",
      "                                                                                                  \n",
      " tf_conv_178 (TFConv)           (1, 40, 40, 117)     42237       ['tfc3_24[0][0]']                \n",
      "                                                                                                  \n",
      " tfc3_25 (TFC3)                 (1, 40, 40, 110)     101498      ['tf_conv_178[0][0]']            \n",
      "                                                                                                  \n",
      " tf_conv_186 (TFConv)           (1, 20, 20, 255)     252705      ['tfc3_25[0][0]']                \n",
      "                                                                                                  \n",
      " tfc3_26 (TFC3)                 (1, 20, 20, 252)     617729      ['tf_conv_186[0][0]']            \n",
      "                                                                                                  \n",
      " tf_conv_196 (TFConv)           (1, 10, 10, 512)     1161728     ['tfc3_26[0][0]']                \n",
      "                                                                                                  \n",
      " tfc3_27 (TFC3)                 (1, 10, 10, 500)     1167880     ['tf_conv_196[0][0]']            \n",
      "                                                                                                  \n",
      " tfsppf_3 (TFSPPF)              (1, 10, 10, 501)     606711      ['tfc3_27[0][0]']                \n",
      "                                                                                                  \n",
      " tf_conv_204 (TFConv)           (1, 10, 10, 251)     126002      ['tfsppf_3[0][0]']               \n",
      "                                                                                                  \n",
      " tf_upsample_6 (TFUpsample)     (1, 20, 20, 251)     0           ['tf_conv_204[0][0]']            \n",
      "                                                                                                  \n",
      " tf_concat_12 (TFConcat)        (1, 20, 20, 503)     0           ['tf_upsample_6[0][0]',          \n",
      "                                                                  'tfc3_26[0][0]']                \n",
      "                                                                                                  \n",
      " tfc3_28 (TFC3)                 (1, 20, 20, 232)     352744      ['tf_concat_12[0][0]']           \n",
      "                                                                                                  \n",
      " tf_conv_210 (TFConv)           (1, 20, 20, 120)     27960       ['tfc3_28[0][0]']                \n",
      "                                                                                                  \n",
      " tf_upsample_7 (TFUpsample)     (1, 40, 40, 120)     0           ['tf_conv_210[0][0]']            \n",
      "                                                                                                  \n",
      " tf_concat_13 (TFConcat)        (1, 40, 40, 230)     0           ['tf_upsample_7[0][0]',          \n",
      "                                                                  'tfc3_25[0][0]']                \n",
      "                                                                                                  \n",
      " tfc3_29 (TFC3)                 (1, 40, 40, 85)      77161       ['tf_concat_13[0][0]']           \n",
      "                                                                                                  \n",
      " tf_conv_216 (TFConv)           (1, 20, 20, 120)     91920       ['tfc3_29[0][0]']                \n",
      "                                                                                                  \n",
      " tf_concat_14 (TFConcat)        (1, 20, 20, 240)     0           ['tf_conv_216[0][0]',            \n",
      "                                                                  'tf_conv_210[0][0]']            \n",
      "                                                                                                  \n",
      " tfc3_30 (TFC3)                 (1, 20, 20, 154)     224249      ['tf_concat_14[0][0]']           \n",
      "                                                                                                  \n",
      " tf_conv_222 (TFConv)           (1, 10, 10, 207)     287109      ['tfc3_30[0][0]']                \n",
      "                                                                                                  \n",
      " tf_concat_15 (TFConcat)        (1, 10, 10, 458)     0           ['tf_conv_222[0][0]',            \n",
      "                                                                  'tf_conv_204[0][0]']            \n",
      "                                                                                                  \n",
      " tfc3_31 (TFC3)                 (1, 10, 10, 229)     859630      ['tf_concat_15[0][0]']           \n",
      "                                                                                                  \n",
      " tf_muli_head_3 (TFMuliHead)    ((1, 2100, 33),      16475       ['tfc3_29[0][0]',                \n",
      "                                 (1,))                            'tfc3_30[0][0]',                \n",
      "                                                                  'tfc3_31[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (1, 2100, 4)        0           ['tf_muli_head_3[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.split_2 (TFOpLambda)        [(1, 2100, 1),       0           ['tf.__operators__.getitem_6[0][0\n",
      "                                 (1, 2100, 1),                   ]']                              \n",
      "                                 (1, 2100, 1),                                                    \n",
      "                                 (1, 2100, 1)]                                                    \n",
      "                                                                                                  \n",
      " tf.math.truediv_8 (TFOpLambda)  (1, 2100, 1)        0           ['tf.split_2[0][3]']             \n",
      "                                                                                                  \n",
      " tf.math.truediv_9 (TFOpLambda)  (1, 2100, 1)        0           ['tf.split_2[0][2]']             \n",
      "                                                                                                  \n",
      " tf.math.truediv_10 (TFOpLambda  (1, 2100, 1)        0           ['tf.split_2[0][3]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_11 (TFOpLambda  (1, 2100, 1)        0           ['tf.split_2[0][2]']             \n",
      " )                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.math.subtract_4 (TFOpLambda  (1, 2100, 1)        0           ['tf.split_2[0][1]',             \n",
      " )                                                                'tf.math.truediv_8[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLambda  (1, 2100, 1)        0           ['tf.split_2[0][0]',             \n",
      " )                                                                'tf.math.truediv_9[0][0]']      \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (1, 2100, 1)        0           ['tf.split_2[0][1]',             \n",
      " mbda)                                                            'tf.math.truediv_10[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (1, 2100, 1)        0           ['tf.split_2[0][0]',             \n",
      " mbda)                                                            'tf.math.truediv_11[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (1, 2100, 1)        0           ['tf_muli_head_3[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (1, 2100, 28)       0           ['tf_muli_head_3[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (1, 2100, 4)         0           ['tf.math.subtract_4[0][0]',     \n",
      "                                                                  'tf.math.subtract_5[0][0]',     \n",
      "                                                                  'tf.__operators__.add_4[0][0]', \n",
      "                                                                  'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (1, 2100, 28)       0           ['tf.__operators__.getitem_7[0][0\n",
      " )                                                               ]',                              \n",
      "                                                                  'tf.__operators__.getitem_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,041,565\n",
      "Trainable params: 0\n",
      "Non-trainable params: 6,041,565\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size, ch, *imgsz = (1,3,320,320)  # BCHW\n",
    "print(imgsz)\n",
    "tf_model = tfmodel\n",
    "im = tf.zeros((batch_size, *imgsz, ch))  # BHWC order for TensorFlow\n",
    "# _ = tf_model.predict(im, tf_nms, agnostic_nms, topk_per_class, topk_all, iou_thres, conf_thres)\n",
    "inputs = tf.keras.Input(shape=(*imgsz, ch), batch_size= batch_size)\n",
    "outputs = tf_model.predict(inputs)\n",
    "print('debug shape output : ',outputs)\n",
    "keras_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "keras_model.trainable = False\n",
    "\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be690f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 10:54:42.897640: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 3\n",
      "2023-12-05 10:54:42.902772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19308 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2023-12-05 10:54:42.903184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21716 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:18:00.0, compute capability: 8.6\n",
      "2023-12-05 10:54:42.903557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 20871 MB memory:  -> device: 2, name: NVIDIA RTX A5000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_head_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# convert saved model\n",
    "\n",
    "f = 'multi_head_saved_model'\n",
    "tf_nms = False\n",
    "spec = tf.TensorSpec(keras_model.inputs[0].shape, keras_model.inputs[0].dtype)\n",
    "m = tf.function(lambda x: keras_model(x))  # full model\n",
    "m = m.get_concrete_function(spec)\n",
    "frozen_func = convert_variables_to_constants_v2(m)\n",
    "tfm = tf.Module()\n",
    "tfm.__call__ = tf.function(lambda x: frozen_func(x)[:4] if tf_nms else frozen_func(x), [spec])\n",
    "tfm.__call__(im)\n",
    "tf.saved_model.save(tfm,\n",
    "                    f,\n",
    "                    options=tf.saved_model.SaveOptions(experimental_custom_gradients=False) if check_version(\n",
    "                        tf.__version__, '2.6') else tf.saved_model.SaveOptions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13ce3f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 10:54:45.441998: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 3\n",
      "2023-12-05 10:54:45.446762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19308 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2023-12-05 10:54:45.447143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21716 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:18:00.0, compute capability: 8.6\n",
      "2023-12-05 10:54:45.447489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 20871 MB memory:  -> device: 2, name: NVIDIA RTX A5000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./multi_head.pb'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export pb\n",
    "f = Path('./multi_head.pb')\n",
    "m = tf.function(lambda x: keras_model(x))  # full model\n",
    "m = m.get_concrete_function(tf.TensorSpec(keras_model.inputs[0].shape, keras_model.inputs[0].dtype))\n",
    "frozen_func = convert_variables_to_constants_v2(m)\n",
    "frozen_func.graph.as_graph_def()\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph, logdir=str(f.parent), name=f.name, as_text=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7418bc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 10:54:55.216379: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-05 10:54:55.216434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-05 10:54:55.216440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file best_web_prune_066_s_model_int8_320x320_3_anchors_box_score_wo_nms_od_zoomin_head/model.json...\n"
     ]
    }
   ],
   "source": [
    "f = 'best_web_prune_066_s_model_int8_320x320_3_anchors_box_score_wo_nms_od_zoomin_head'\n",
    "# f = str(file).replace('.pt', '_web_prune_066_s_model_int8_320x320_3_anchors_box_score_wo_nms_od')  # js dir\n",
    "f_pb = './multi_head.pb'  # *.pb path\n",
    "# f_pb = ''\n",
    "f_json = f'{f}/model.json'  # *.json path\n",
    "\n",
    "int8 = True\n",
    "\n",
    "args = [\n",
    "    'tensorflowjs_converter',\n",
    "    '--input_format=tf_frozen_model',\n",
    "    '--quantize_uint8' if int8 else '',\n",
    "    '--output_node_names=Identity,Identity_1,Identity_2',\n",
    "    str(f_pb),\n",
    "    str(f), ]\n",
    "subprocess.run([arg for arg in args if arg], check=True)\n",
    "\n",
    "json = Path(f_json).read_text()\n",
    "with open(f_json, 'w') as j:  # sort JSON Identity_* in ascending order\n",
    "    subst = re.sub(\n",
    "        r'{\"outputs\": {\"Identity.?.?\": {\"name\": \"Identity.?.?\"}, '\n",
    "        r'\"Identity.?.?\": {\"name\": \"Identity.?.?\"}, '\n",
    "        r'\"Identity.?.?\": {\"name\": \"Identity.?.?\"}}}', r'{\"outputs\": {\"Identity\": {\"name\": \"Identity\"}, '\n",
    "        r'\"Identity_1\": {\"name\": \"Identity_1\"}, '\n",
    "        r'\"Identity_2\": {\"name\": \"Identity_2\"}}}', json)\n",
    "    j.write(subst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78db7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv web_model best_web_prune_066_s_model_int8_320x320_3_anchors_box_score_wo_nms_od_zoomin_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5be2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf best_web_prune_066_s_model_int8_320x320_3_anchors_box_score_wo_nms_od_zoomin_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2745ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
